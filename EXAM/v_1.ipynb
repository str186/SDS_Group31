{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, Imputer\n",
    "from sklearn.metrics import mean_squared_error as mse, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and structure it\n",
    "### Write wanted sample, set 0 if all data wanted:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sample data\n",
      "Finished making sample data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now creating Dummy of sexual orientation\n",
      "\n",
      "Structuring complete\n"
     ]
    }
   ],
   "source": [
    "#IMPORTANT : THIS IS IN EXCEL FORMAT, CHANGE TO CSV IF YOUR FILE IS NOT XLSX\n",
    "df_q_list = pd.read_excel(\"question_data.xlsx\")\n",
    "\n",
    "print(\"Making sample data\")\n",
    "# TAKE A SAMPLE OF DATA\n",
    "filename = \"user_data_public.csv\"\n",
    "\n",
    "if sample_dataset != 0:\n",
    "    n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "    s = sample_dataset #desired sample size\n",
    "    skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "    df_master = pd.read_csv(filename, \n",
    "                            skiprows=skip, \n",
    "                            dtype = object)\n",
    "else:\n",
    "    df_master = pd.read_csv(filename, skiprows=skip, dtype = object)\n",
    "print(\"Finished making sample data\")\n",
    "\n",
    "# Take only questions with n answers and put the questions in a column\n",
    "#df_q.N.plot(kind=\"hist\")\n",
    "n_answers = 20000\n",
    "df_keep = pd.DataFrame()\n",
    "df_keep['keep_questions'] = df_q_list[df_q_list[\"N\"]>n_answers].index\n",
    "\n",
    "#Keep only questions that are also in master dataframe and make new dataframe with most answered questions\n",
    "df_keep = df_keep[df_keep[\"keep_questions\"].isin(list(df_master.columns.values))]\n",
    "df_master_keep = df_master[list(df_keep[\"keep_questions\"])]\n",
    "\n",
    "#Count not missing each row i.e: number of answered questions by each preson:\n",
    "df_master_keep[\"answered_questions\"] = df_master_keep.notnull().sum(axis=1).copy()\n",
    "\n",
    "#Choose only rows with at least n answered questions\n",
    "n_questions = 400\n",
    "df_clean_v1 = df_master_keep[df_master_keep[\"answered_questions\"]>n_questions]\n",
    "\n",
    "#Create dummy for sexual orientation, where 1 = NOT STRAIGHT\n",
    "print(\"Now creating Dummy of sexual orientation\")\n",
    "sexual_orientation = []\n",
    "for x in df_clean_v1['d_orientation']:\n",
    "    if pd.isnull(x):\n",
    "        sexual_orientation.append(1) #Since we have persons answered over a 1000 questions, so if they have not answered their sexual orientation we assume they are either uncertain or dont want to disclose because of fear of persecution/judgement from peers\n",
    "    elif x != \"Straight\":\n",
    "        sexual_orientation.append(1)\n",
    "    else:\n",
    "        sexual_orientation.append(0)\n",
    "        \n",
    "#Turn it into a dataframe and put labels from dataframe on\n",
    "y = pd.DataFrame(sexual_orientation, index = df_clean_v1.index)\n",
    "\n",
    "# Drop sexual orientation from master dataframe\n",
    "df_clean_v1.drop(columns = [\"d_orientation\"], inplace = True)\n",
    "print()\n",
    "\n",
    "#Remove the most problematic questions, and them make all of the categorical variables dummiew\n",
    "df_prep = df_clean_v1.drop(columns = [\"q1401\", \"q80928\", \"q546\", \"q1040\"])\n",
    "df_dummy = pd.get_dummies(df_prep, dummy_na = False) #When missing giver 0 to all dummies created for the quesion with the missing value\n",
    "#df_dummy.fillna(value = -1, inplace = True) #If missing insert -1 # This code does not work\n",
    "X = df_dummy\n",
    "\n",
    "#INSERT MISSING VALUES BACK INTO THE DUMMIES FOR LATER IMPUTER\n",
    "for i in list(df_keep[\"keep_questions\"].head()):\n",
    "    X.loc[df_prep[i].isnull(), X.columns.str.startswith(i+\"_\")] = np.nan\n",
    "    \n",
    "print(\"Structuring complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRUCTURING COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW DEFINING FUNCTIONS AND SPLITTING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions to be used for parallel computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_paralel(x):\n",
    "    tree = DecisionTreeClassifier(criterion=\"gini\", max_depth= x, random_state=1)  \n",
    "    accuracy_ = []\n",
    "    for train_idx, val_idx in kfolds.split(X_dev, y_dev):\n",
    "\n",
    "        X_train, y_train, = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx] \n",
    "        \n",
    "        X_train = pd.DataFrame(im.fit_transform(X_train),index = X_train.index)\n",
    "        X_val = pd.DataFrame(im.transform(X_val), index = X_val.index)\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_val)\n",
    "        accuracy_.append(accuracy_score(y_val, y_pred))\n",
    "    print(\"This was the \"+str(x)+\" iteration\", (dt.now() - start).total_seconds())\n",
    "    return accuracy_\n",
    "\n",
    "def forest_paralel(x):\n",
    "    forest = RandomForestClassifier(criterion=\"gini\", max_depth= x, random_state=1)  \n",
    "    accuracy_ = []\n",
    "    for train_idx, val_idx in kfolds.split(X_dev, y_dev):\n",
    "\n",
    "        X_train, y_train, = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx] \n",
    "        \n",
    "        X_train = pd.DataFrame(im.fit_transform(X_train),index = X_train.index)\n",
    "        X_val = pd.DataFrame(im.transform(X_val), index = X_val.index)\n",
    "        forest.fit(X_train, y_train.values.ravel())\n",
    "        y_pred = forest.predict(X_val)\n",
    "        accuracy_.append(accuracy_score(y_val, y_pred))\n",
    "    print(\"This was the \"+str(x)+\" iteration\", (dt.now() - start).total_seconds())\n",
    "    return accuracy_\n",
    "\n",
    "def logit_reg(c_param):\n",
    "    logit_pipe = make_pipeline(LogisticRegression(random_state= 1, C = c_param)) \n",
    "    accuracy_ = []\n",
    "    for train_idx, val_idx in kfolds.split(X_dev, y_dev):\n",
    "        X_train, y_train, = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx] \n",
    "        \n",
    "        X_train = pd.DataFrame(im.fit_transform(X_train),index = X_train.index)\n",
    "        X_val = pd.DataFrame(im.transform(X_val), index = X_val.index)\n",
    "\n",
    "        logit_pipe.fit(X_train, y_train.values.ravel())\n",
    "        y_pred = logit_pipe.predict(X_val)\n",
    "        accuracy_.append(accuracy_score(y_val, y_pred))  \n",
    "    print(\"This was the \"+str(x)+\" iteration\", (dt.now() - start).total_seconds())\n",
    "    return accuracy_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We make a sample where 80pct. of the data is used for development, and the number of kfolds to be used and type of imputer to replace the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "kfolds = KFold(n_splits=10)\n",
    "\n",
    "# Missing in the dummies will be set to the mean of the answers by default\n",
    "im = Imputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit, Decisiontree and Randomforest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit regression, where we itterate over different values for the regularization parameter and keep the optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 91.133668\n",
      "Optimal hyperparameter: 0.6 with accuracy: [ 0.90936634]\n"
     ]
    }
   ],
   "source": [
    "# RUN THE KFOLDS TO FINT THE OPTIMAL HYPERPARAMETER\n",
    "\n",
    "p = Pool(4)\n",
    "\n",
    "input_ = np.linspace(0.1,1,10)\n",
    "output_ = []\n",
    "accuracy = []\n",
    "start = dt.now()\n",
    "for result in p.imap(logit_reg, input_):\n",
    "    output_.append(result)\n",
    "p.close()\n",
    "temp = pd.DataFrame(output_).mean(axis=1)\n",
    "temp.index = input_\n",
    "optimal_l = temp.nlargest(1)\n",
    "print(\"Time:\", (dt.now() - start).total_seconds())\n",
    "print(\"Optimal hyperparameter: \"+ str(optimal_l.index[0]) + \" with accuracy: \" + str(optimal_l.values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901913875598\n",
      "\n",
      "[[680  29]\n",
      " [ 53  74]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# RUN THE LOGIT WITH OPTIMAL INDEX\n",
    "\n",
    "logit_pipe = make_pipeline(LogisticRegression(random_state= 1, C = optimal_l.index[0]))\n",
    "\n",
    "\n",
    "X_dev = pd.DataFrame(im.fit_transform(X_dev), index= X_dev.index)\n",
    "X_test = pd.DataFrame(im.transform(X_test), index= X_test.index)\n",
    "\n",
    "logit_pipe.fit(X_dev, y_dev.values.ravel())\n",
    "predict = pd.DataFrame(logit_pipe.predict(X_test),index = y_test.index)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print()\n",
    "print(print(confusion_matrix(y_test,predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was the 1 iteration 2504.129164\n",
      "This was the 2 iteration 2505.684552\n",
      "This was the 3 iteration 2507.244761\n",
      "This was the 4 iteration 2508.687648\n",
      "This was the 5 iteration 2520.971194\n",
      "This was the 6 iteration 2523.884034\n",
      "This was the 7 iteration 2526.930939\n",
      "This was the 8 iteration 2529.314511\n",
      "This was the 9 iteration 2539.327477\n",
      "This was the 10 iteration 2541.560915\n",
      "Time: 51.497737\n",
      "Optimal hyperparameter: 6 with accuracy: [ 0.94465725]\n"
     ]
    }
   ],
   "source": [
    "p = Pool(4)\n",
    "\n",
    "input_ = range(1,11)\n",
    "output_ = []\n",
    "accuracy = []\n",
    "start = dt.now()\n",
    "for result in p.imap(tree_paralel, input_):\n",
    "    output_.append(result)\n",
    "p.close()\n",
    "temp = pd.DataFrame(output_).mean(axis = 1)\n",
    "temp.index = input_\n",
    "optimal_t = temp.nlargest(1)\n",
    "print(\"Time:\", (dt.now() - start).total_seconds())\n",
    "print(\"Optimal hyperparameter: \"+ str(optimal_t.index[0]) + \" with accuracy: \" + str(optimal_t.values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941387559809\n",
      "\n",
      "[[687  22]\n",
      " [ 27 100]]\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion='gini', max_depth= optimal_t.index[0], random_state=1)\n",
    "\n",
    "X_dev = pd.DataFrame(im.fit_transform(X_dev), index= X_dev.index)\n",
    "X_test = pd.DataFrame(im.transform(X_test), index= X_test.index)\n",
    "\n",
    "\n",
    "tree.fit(X_dev, y_dev)\n",
    "predict = pd.DataFrame(tree.predict(X_test),index = y_test.index)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print()\n",
    "print(confusion_matrix(y_test,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was the 10 iteration 75.521591\n",
      "This was the 11 iteration 75.75712\n",
      "This was the 12 iteration 75.945254\n",
      "This was the 13 iteration 76.07596\n",
      "This was the 14 iteration 89.407084\n",
      "This was the 15 iteration 89.741772\n",
      "This was the 16 iteration 89.860972\n",
      "This was the 17 iteration 90.150475\n",
      "This was the 18 iteration 100.996613\n",
      "This was the 19 iteration 101.217193\n",
      "This was the 20 iteration 101.299086\n",
      "Time: 39.269115\n",
      "Optimal hyperparameter: 12 with accuracy: [ 0.85043614]\n"
     ]
    }
   ],
   "source": [
    "p = Pool(4)\n",
    "\n",
    "input_ = range(10,21)\n",
    "output_ = []\n",
    "accuracy = []\n",
    "start = dt.now()\n",
    "for result in p.imap(forest_paralel, input_):\n",
    "    output_.append(result)\n",
    "p.close()\n",
    "temp = pd.DataFrame(output_).mean(axis = 1)\n",
    "temp.index = input_\n",
    "optimal_f = temp.nlargest(1)\n",
    "print(\"Time:\", (dt.now() - start).total_seconds())\n",
    "print(\"Optimal hyperparameter: \"+ str(optimal_f.index[0]) + \" with accuracy: \" + str(optimal_f.values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876794258373\n",
      "\n",
      "[[705   4]\n",
      " [ 99  28]]\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(criterion='gini', max_depth= optimal_f.index[0], random_state=1)\n",
    "\n",
    "X_dev = pd.DataFrame(im.fit_transform(X_dev), index= X_dev.index)\n",
    "X_test = pd.DataFrame(im.transform(X_test), index= X_test.index)\n",
    "\n",
    "\n",
    "forest.fit(X_dev, y_dev.values.ravel())\n",
    "predict = pd.DataFrame(forest.predict(X_test),index = y_test.index)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print()\n",
    "print(confusion_matrix(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "n_estimators_rng = np.unique(np.logspace(0,2,20).astype(np.int64))\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=10,random_state=1, max_depth= optimal_f.index[0])\n",
    "X = pd.DataFrame(im.fit_transform(X), index= X.index)\n",
    "\n",
    "train_scores, test_scores = \\\n",
    "    validation_curve(estimator=clf_rf, \n",
    "                     X=X, \n",
    "                     y=y,\n",
    "                     param_name='n_estimators', \n",
    "                     param_range=n_estimators_rng,\n",
    "                     cv=5)\n",
    "    \n",
    "f,ax = plt.subplots()\n",
    "\n",
    "ax.plot(n_estimators_rng, np.mean(train_scores, 1), label='Test scores')\n",
    "ax.plot(n_estimators_rng, np.mean(test_scores, 1), label='Train scores') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
